The first layer we are looking at: The Micro-layer. Here, things actually happen. This is the layer that encodes and executes business logic – without the respective logic for it, our service cannot exhibit particular functionality. While there are a lot of ways to execute a desired functionality pattern, there are fortunate and unfortunate ways of completing any kind of task. One way might be more efficient than the other – maybe the other one is more precise. Depending on priorities, resources, strategy and internal competence, one way of executing functionality might be vastly superior to others. If you receive the task of heaving a stone up a mountain, the most apparent solution is just pushing it up, straining and exhausting your body. 

However, if you can anticipate that you will need to perform this task repeatedly, it might be worth considering building a mechanism that performs the work for you, even if it means more preperation and a longer time to execution – you are making a short-term sacrifice in order to optimize your efforts long-term.

> Engineering doesn't just make it work, the way it is built directly affects your service. Only if design and system architecture are aligned can your technology empower world-class user experiences.

System architecture choices directly impact user experience. Often times, the underlying technology is the reason a service is capable of excercising is fundamental performances in the first place. 

Many times, the core value definition of a service directly references its technical capabilities. For example, one of the main selling points of Google Docs, an online document editing platform, is its real-time document sharing, where multiple parties can work on the same document over the Internet. This core offering of the service has immense implications for its system architecture: Communication and databases need to work in real-time, instantly synchronize across multiple clients, and be built in a performance-driven way. This illustrates why the technology behind a service is not just a necessity, but a core part of its design as a whole; if Google Docs did not place a strategic importance on real-time sharing, implementing a traditional write & read mechanic for document sharing would have been much cheaper and faster. 

Now that we have established the importance of considering technology as a fundamental design factor in services, let us explore some fundamental concepts from the world of Software Engineering – from which, as you will see, we can learn a lot.

## Engineering at scale

The concept of _technical debt_ defines how hard a codebase is to expand, adjust and scale – in short, to maintain. Software Engineering pioneers quickly realized that duplicating functional mechanisms skyrockets technical debt and makes your code hard to maintain. If your service needs to send 30 slightly different kinds of invoices, but each of these invoices are generated by a specific mechanism that was copied, slightly adjusted, and then deployed in production, fixing an issue that was introduced in the very beginning means performing 30 times the work it would have taken if all invoices were processed in a single place – and this is assuming the copied patterns have not substantially diverged in the way they work. 

Thus, one of the most important paradigms in software engineering is DRY coding – Don't repeat yourself.

## Keeping it dry

DRY means: Instead of duplicating functionality, express it as a general mechanism and move it to a place that allows any dependant mechanism to execute it on demand. Any sufficiently often occuring constant should be defined so that any dependant function simply references this single, global definition. It is simple to understand why going through this effort is worth it on the most basic of levels: Imagine rebranding your service, and the primary color of all user interface elements should change. If you have told every button, checkbox and link its color individually, you are facing the excruciating task of hunting down every single one of these occurences and changing them individually. If you have referenced a _single source of truth_ however, you can change your variable in one place, and the change will propagate through all of your interfaces automatically.

The concept of storing fundamental constants and repetitive patterns globally in the context of visual design for digital products is frequently applied as parts of _Design Systems_.

> A design system offers a library of visual style, components, and other concerns documented and released by an individual, team or community as code and design tools so that adopting products can be more efficient and cohesive. (https://medium.com/eightshapes-llc/defining-design-systems-6dd4b03e0ff6)

A specific implementation of a design system, Lightning Design by CRM behemoth Salesforce, goes a step further and proposes a single source of truth for _atomic constants_, the very fundamental values that encode and express a brand visually.

> Design tokens are the visual design atoms of the design system — specifically, they are named entities that store visual design attributes. We use them in place of hard-coded values (such as hex values for color or pixel values for spacing) in order to maintain a scalable and consistent visual system for UI development.

In essence, this allows sharing constants like colors not just across one application, but a full suite of implementations. If the source of truth is adjusted, everything updates globally.

<img src="/thesis/img/designTokens.svg">

This exact same pattern applies to raw functionality as well – going back to our invoice example; if invoice rendering were defined in a single place and all dependants of invoice generation simply referenced this single function, fixing an issue with it would instantaneously apply to the system in its entirety. Understanding this simple paradigm opens up a whole world of possibilities for system architecture as a whole – and this architecture, let me remind you, influences the behaviour and quality of our service's performance directly.

## The Unix Philosophy

A well-known manifestation of the DRY paradigm is the Unix Philosophy, originated by Computer Science pioneer Ken Thompson in the late 1970s. Unix is a command-line based operating system developed at Bell Labratories that has since grown to be the basis of modern operating systems such as Ubuntu and Mac OS to this date. If you open the Terminal application on a MacBook today, you are interacting with an Unix system directly. User interfaces on these systems are simply executing commands like these behind the scenes. 

The Unix philosophy, summarized by computer scientist Peter H. Saulus in 1994, entails: 

- Write programs that do one thing and do it well.
- Write programs to work together.
- Write programs to handle text streams, because that is a universal interface.

The first paradigm represents a striking similarity to DRY. In Unix, it is possible to string multiple commands together and _pipe_ (represented by the pipe character | ) the first one's input into the next. For example, the command `ls` (for _list_) simply prints the names of files and folders in the current working directory to the screen: 

```
$ ls
uglyCat.jpg
beautifulCat.jpg
dog.jpg
```

Another Unix application, `grep`, takes an input and outputs a filtered version based on a search term. By _piping_ the output of `ls` into `grep`, we can search the working directory's contents. Let us say we want to find the image of the dog in this folder. 

```
$ ls | grep "dog"
dog.jpg
```

As you can see, `grep` filtered the output of `ls` so that the resulting output is only the line including the term "dog". 

This demonstrates the paradigm perfectly: Both `ls` and `grep` do one thing, and they do it well. By stringing together multiple applications and making them interact with each other, we can quickly perform much more complicated patterns.

What does this have to do with services?, you might ask – let me tell you.


## Service Thinking in System Architecture

Let us think about what `grep` and `ls` really are. We, as the user, have a need – we need to find a file in our directory. `ls` and `grep` individually perform parts of what is needed in order to generate an outcome that satisfies our need – a filtered list of files in a directory. 

You might already be able to tell where this is going – we can treat `ls` and `grep` as _services_ as defined in Chapter 1. For the sake of simplicity, let us assume we write a simple script that encapsulates `ls`'s output piped into `grep` as a single command – `sd`, for _search directory_.

```
$ sd "dog"
dog.jpg
```

Now, we can define `sd` as our macroscopic service – with `ls` and `grep` acting as the atomic functionality inside, allowing `sD` to perform. 

<img src="/thesis/img/sdAsService.svg">

Since `sd` is very simple and we know exactly just how it achieves its outcome, we can go a step further and visualize the performance. Now, `sd` acts as the user to our two other services – `ls` and `grep`. By chaining our two bits of atomic functionality together, `sd` is capable of performing a vastly more complicated action. 

<img src="/thesis/img/sdMicroservices.svg">

Both `ls` and `cd` are entirely unaware of their role in this system. They simply perform the action they are designed to perform, nothing more, nothing else. They receive an input and provide an output – how said output is processed afterwards is irrelevant. 

In this example, `sd` is our macroscopic _service_, and `ls` and `cd` act as _microservices_.

### Microservices in real-world applications

More and more frequently, sophisticated systems are designed with the _Microservice_ paradigm, directly derived from DRY and the Unix philosophy. In a Mircoservice pattern, business logic is split into _single responsibility_ atomic bits that each _do one thing, and do it well_. These services are _decoupled_, meaning they each have their own seperate place to live in and act, and do not know or care about others performing tasks around them.

> A microservice should be so tiny that when someone wants to adjust its behaviour, it's a no-brainer to just rewrite it from scratch.

This kind of architecture comes with lots of benefits. Each little mechanism is ideally so small that its functionality can be described and documented in an extremely simple to understand way. More complex logic is simply a result of orchestrating individual small mechanisms in order to achieve the desired end result. 